import pdfplumber
import re
import pandas as pd
import os

# Paths
folder_path = r"***File location here***"
composition_csv_path = r"***File location here***"

# Composition Indices Fields
composition_indices_fields = {
    "Total body weight \(kg\)": "Total Body Weight (kg)",
    "Body mass index \(kg/m²\) \(BMI\)": "BMI (kg/m²)",
    "Basal metabolic rate \(kcal/Day\)": "Basal Metabolic Rate (kcal/day)",
    "Total body % Fat": "Total Body Fat (%)",
    "Fat mass/height² \(kg/m²\) \(FMI\)": "Fat Mass Index (FMI)",
    "Android/Gynoid % fat ratio": "Android/Gynoid Fat Ratio",
    "Trunk/legs % fat ratio": "Trunk/Legs Fat Ratio",
    "Trunk/limb fat mass ratio": "Trunk/Limb Fat Mass Ratio",
    "Visceral Adipose Tissue Area \(cm²\)": "Visceral Fat Area (cm²)",
    "Visceral Adipose Tissue Mass \(g\)": "Visceral Fat Mass (g)",
    "Visceral Adipose Tissue Volume \(cm³\)": "Visceral Fat Volume (cm³)",
    "Subcutaneous Adipose Tissue Area \(cm²\)": "Subcutaneous Fat Area (cm²)",
    "Total body % Lean": "Total Lean Body (%)",
    "Lean mass/height² \(kg/m²\)": "Lean Mass Index (kg/m²)",
    "Append\. Lean Mass/Height² \(kg/m²\)": "Appendicular Lean Mass Index (kg/m²)",
    "Total body % Bone": "Total Bone Mass (%)",
}

def extract_composition_indices(text, unique_id, patient_name, scan_date):
    """ Extract composition indices from the Composition Indices section. """
    indices_data = {"Unique ID": unique_id, "Patient Name": patient_name, "Scan Date": scan_date}
    for field, friendly_name in composition_indices_fields.items():
        pattern = rf"{field}\s+([\d.]+)"
        match = re.search(pattern, text)
        indices_data[friendly_name] = float(match.group(1)) if match else None
    return indices_data

def parse_dexa_text_for_composition_indices(pdf_path):
    """ Parse the PDF and extract only the composition indices. """
    composition_rows = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()

            # Extract scan date
            scan_date_match = re.search(r"Scan Date :([\d/]+)", text)
            scan_date = scan_date_match.group(1) if scan_date_match else "01/01/2000"
            try:
                scan_date = pd.to_datetime(scan_date, format="%d/%m/%Y").strftime("%d-%m-%Y")
            except ValueError:
                scan_date = "unknown_date"

            # Extract patient name
            patient_match = re.search(r"Patient :(.*?)\s+Height", text)
            patient_name = patient_match.group(1).strip().replace(" ", "_") if patient_match else "unknown_patient"

            # Create unique ID
            unique_id = f"{patient_name}_{scan_date}"

            # Extract composition indices
            composition_data = extract_composition_indices(text, unique_id, patient_name, scan_date)
            composition_rows.append(composition_data)
    
    return composition_rows

def update_composition_indices_csv(folder_path, composition_csv_path):
    headers = ["Unique ID", "Patient Name", "Scan Date"] + list(composition_indices_fields.values())

    # Collect composition indices from all PDF files in the folder
    all_composition_rows = []
    pdf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(".pdf")]

    print(f"Found {len(pdf_files)} PDF files in folder: {folder_path}")
    for pdf_file in pdf_files:
        print(f"Processing file: {pdf_file}")
        composition_rows = parse_dexa_text_for_composition_indices(pdf_file)
        if composition_rows:
            all_composition_rows.extend(composition_rows)

    # Create DataFrame from parsed data
    new_data = pd.DataFrame(all_composition_rows)

    # Ensure consistent date formatting
    new_data["Scan Date"] = pd.to_datetime(new_data["Scan Date"], format="%d-%m-%Y", errors="coerce")
    new_data["Scan Date"] = new_data["Scan Date"].dt.strftime("%d-%m-%Y")

    # Check if the composition CSV exists
    if os.path.exists(composition_csv_path):
        composition_df = pd.read_csv(composition_csv_path)
        composition_df["Scan Date"] = pd.to_datetime(composition_df["Scan Date"], format="%d-%m-%Y", errors="coerce")
        composition_df["Scan Date"] = composition_df["Scan Date"].dt.strftime("%d-%m-%Y")
    else:
        composition_df = pd.DataFrame(columns=headers)

    # Append new data to the composition indices CSV
    updated_df = pd.concat([composition_df, new_data]).drop_duplicates(subset=["Unique ID"], keep="last")

    # Save the updated composition indices CSV
    updated_df.to_csv(composition_csv_path, index=False)
    print(f"Composition Indices CSV updated successfully! Total records: {len(updated_df)}")

# Run the batch update
update_composition_indices_csv(folder_path, composition_csv_path)
